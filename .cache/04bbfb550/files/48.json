{"contents":"exports.__esModule = true;\nvar lexer_1 = __fusereq(13);\nvar position_1 = __fusereq(49);\nclass TokenStream {\n  constructor(text) {\n    this.pos = 0;\n    this.tokens = lexer_1.getTokens(text).filter(t => t.type != 'COMMENT');\n  }\n  consume() {\n    const token = this.tokens[this.pos];\n    if (token) {\n      this.pos += 1;\n    }\n    return token;\n  }\n  peek() {\n    return this.tokens[this.pos];\n  }\n  last() {\n    return this.tokens[this.pos - 1];\n  }\n  expectToken(expectedType) {\n    const actual = this.consume();\n    if (!actual) {\n      throw new position_1.ParseError(`Expected \"${expectedType}\" token but found none.`, position_1.token2pos(this.last()));\n    }\n    if (actual.type != expectedType) {\n      throw new position_1.ParseError(`Expected \"${expectedType}\" token type but found \"${actual.type}\".`, position_1.token2pos(actual));\n    }\n    return actual;\n  }\n}\nexports.TokenStream = TokenStream;\n","sourceMap":"{\"version\":3,\"sources\":[\"src/tokenstream.ts\"],\"names\":[\"constructor\",\"text\",\"pos\",\"tokens\",\"lexer_1\",\"filter\",\"t\",\"type\",\"consume\",\"token\",\"peek\",\"last\",\"expectToken\",\"expectedType\",\"actual\",\"position_1\"],\"mappings\":\";;;AAGO;EAILA,YAAYC;SAFZC,MAAc;IAGZ,KAAKC,SAASC,kBAAUH,MAAMI,OAAO,AAAAC,KAAKA,EAAEC,QAAQ;;EAGtDC;UACQC,QAAQ,KAAKN,OAAO,KAAKD;QAC3BO;MACF,KAAKP,OAAO;;WAEPO;;EAGTC;WACS,KAAKP,OAAO,KAAKD;;EAG1BS;WACS,KAAKR,OAAO,KAAKD,MAAM;;EAGhCU,YAAiCC;UACzBC,SAAS,KAAKN;SAEfM;gBACOC,mCACKF,uCACbE,qBAAU,KAAKJ;;QAIfG,OAAOP,QAAQM;gBACPE,mCACKF,uCAAuCC,OAAOP,UAC3DQ,qBAAUD;;WAIPA\",\"sourcesContent\":[\"import {Token, TokenType, getTokens} from './lexer';\\nimport {ParseError, token2pos} from './position';\\n\\nexport class TokenStream {\\n  tokens: Token[];\\n  pos: number = 0;\\n\\n  constructor(text: string) {\\n    this.tokens = getTokens(text).filter(t => t.type != 'COMMENT');\\n  }\\n\\n  consume(): Token | undefined {\\n    const token = this.tokens[this.pos];\\n    if (token) {\\n      this.pos += 1;\\n    }\\n    return token;\\n  }\\n\\n  peek(): Token | undefined {\\n    return this.tokens[this.pos];\\n  }\\n\\n  last(): Token {\\n    return this.tokens[this.pos - 1];\\n  }\\n\\n  expectToken<T extends TokenType>(expectedType: T): Token<T> {\\n    const actual = this.consume();\\n\\n    if (!actual) {\\n      throw new ParseError(\\n        `Expected \\\"${expectedType}\\\" token but found none.`,\\n        token2pos(this.last()),\\n      );\\n    }\\n\\n    if (actual.type != expectedType) {\\n      throw new ParseError(\\n        `Expected \\\"${expectedType}\\\" token type but found \\\"${actual.type}\\\".`,\\n        token2pos(actual),\\n      );\\n    }\\n\\n    return actual as Token<T>;\\n  }\\n}\\n\"]}"}